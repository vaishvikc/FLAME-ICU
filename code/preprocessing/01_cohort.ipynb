{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Mortality Model - Cohort Generation\n",
    "\n",
    "This notebook generates the ICU cohort for mortality prediction modeling following the PRD requirements.\n",
    "\n",
    "## Objective\n",
    "Generate a cohort table containing:\n",
    "- `hospitalization_id`\n",
    "- `start_dttm`: ICU admission timestamp\n",
    "- `hour_24_start_dttm`: first ICU hour (may equal start_dttm)\n",
    "- `hour_24_end_dttm`: end of the first 24 hours\n",
    "- `disposition`: binary outcome (1 = expired, 0 = survived)\n",
    "\n",
    "## Cohort Criteria\n",
    "- First 24 hours of first ICU stay\n",
    "- Exclude re-admissions and ICU readmissions\n",
    "- ICU-OR-ICU sequences treated as continuous ICU stay\n",
    "- Minimum 24-hour ICU stay\n",
    "- Adults (â‰¥18 years)\n",
    "- 2020-2021 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyclif import CLIF\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== ICU Mortality Model - Cohort Generation ===\")\n",
    "print(\"Setting up environment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"Load configuration from config.json\"\"\"\n",
    "    config_path = os.path.join( \"config_demo.json\")\n",
    "    \n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = json.load(file)\n",
    "        print(\"âœ… Loaded configuration from config.json\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Configuration file not found. Please create config.json based on the config_template.\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Load configuration\n",
    "config = load_config()\n",
    "print(f\"Site: {config['site']}\")\n",
    "print(f\"Data path: {config['clif2_path']}\")\n",
    "print(f\"File type: {config['filetype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyCLIF\n",
    "clif = CLIF(\n",
    "    data_dir=config['clif2_path'],\n",
    "    filetype=config['filetype'],\n",
    "    timezone=\"US/Eastern\"\n",
    ")\n",
    "\n",
    "print(\"âœ… pyCLIF initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required tables using pyCLIF\n",
    "print(\"Loading required tables...\")\n",
    "clif.initialize([\"adt\", \"hospitalization\", \"patient\"])\n",
    "\n",
    "# Load ADT data\n",
    "adt_df = clif.adt.df.copy()\n",
    "print(f\"ADT data loaded: {len(adt_df)} records\")\n",
    "\n",
    "# Load hospitalization data\n",
    "hosp_df = clif.hospitalization.df.copy()\n",
    "print(f\"Hospitalization data loaded: {len(hosp_df)} records\")\n",
    "\n",
    "# Load patient data\n",
    "patient_df = clif.patient.df.copy()\n",
    "print(f\"Patient data loaded: {len(patient_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt_df.location_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for cohort generation\n",
    "print(\"Preparing data for cohort generation...\")\n",
    "\n",
    "# Merge ADT with hospitalization data\n",
    "icu_data = pd.merge(\n",
    "    adt_df[['hospitalization_id', 'location_category', 'in_dttm', 'out_dttm']],\n",
    "    hosp_df[['patient_id', 'hospitalization_id', 'age_at_admission', 'discharge_category', 'admission_dttm']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged data: {len(icu_data)} records\")\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['in_dttm', 'out_dttm', 'admission_dttm']\n",
    "for col in datetime_cols:\n",
    "    icu_data[col] = pd.to_datetime(icu_data[col])\n",
    "\n",
    "# Handle location categories (convert procedural to OR as in Inference_py.ipynb)\n",
    "icu_data.loc[icu_data['location_category'] == 'procedural', 'location_category'] = 'OR'\n",
    "icu_data['location_category'] = icu_data['location_category'].str.upper()\n",
    "\n",
    "print(\"âœ… Data preparation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICU Cohort Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply initial filters\n",
    "print(\"Applying initial cohort filters...\")\n",
    "\n",
    "# Filter for ICU admissions within 48 hours of hospital admission\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) &\n",
    "   # (icu_data['admission_dttm'].dt.year >= 2020) & (icu_data['admission_dttm'].dt.year <= 2021) &\n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())\n",
    "]['hospitalization_id'].unique()\n",
    "\n",
    "print(f\"Hospitalizations with ICU within 48hr: {len(icu_48hr_check)}\")\n",
    "\n",
    "# Filter to relevant encounters and extend to 72 hours for location tracking\n",
    "icu_data = icu_data[\n",
    "    icu_data['hospitalization_id'].isin(icu_48hr_check) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"Filtered data for processing: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process ICU-OR-ICU sequences (treat as continuous ICU)\n",
    "print(\"Processing ICU-OR-ICU sequences...\")\n",
    "\n",
    "# Sort by admission time and create ranking\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "icu_data[\"RANK\"] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"hospitalization_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n",
    "\n",
    "# Find minimum ICU rank for each hospitalization\n",
    "min_icu = icu_data[icu_data['location_category'] == 'ICU'].groupby('hospitalization_id')['RANK'].min()\n",
    "icu_data = pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['hospitalization_id', 'min_icu']), on='hospitalization_id', how='left')\n",
    "\n",
    "# Filter to locations from first ICU onward\n",
    "icu_data = icu_data[icu_data['RANK'] >= icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "# Convert OR to ICU for continuity (ICU-OR-ICU treated as continuous ICU)\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "print(f\"After ICU-OR-ICU processing: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group consecutive ICU locations\n",
    "print(\"Grouping consecutive ICU locations...\")\n",
    "\n",
    "# Create groups for consecutive locations\n",
    "icu_data['group_id'] = (icu_data.groupby('hospitalization_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('hospitalization_id')['group_id'].cumsum()\n",
    "\n",
    "# Aggregate by groups\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['patient_id', 'hospitalization_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('discharge_category', 'first')\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Grouped data: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply final cohort criteria\n",
    "print(\"Applying final cohort criteria...\")\n",
    "\n",
    "# Find minimum ICU group for each hospitalization\n",
    "min_icu_group = icu_data[icu_data['location_category'] == 'ICU'].groupby('hospitalization_id')['group_id'].min()\n",
    "icu_data = pd.merge(icu_data, pd.DataFrame(zip(min_icu_group.index, min_icu_group.values), columns=['hospitalization_id', 'min_icu_group']), on='hospitalization_id', how='left')\n",
    "\n",
    "# Filter to first ICU stay with minimum 24-hour duration\n",
    "icu_data = icu_data[\n",
    "    (icu_data['min_icu_group'] == icu_data['group_id']) &\n",
    "    (icu_data['max_out_dttm'] - icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final cohort before demographics: {len(icu_data)} records\")\n",
    "\n",
    "# Add 24-hour endpoint\n",
    "icu_data['after_24hr'] = icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "# Select required columns\n",
    "icu_data = icu_data[['patient_id', 'hospitalization_id', 'min_in_dttm', 'max_out_dttm', 'after_24hr', 'age', 'dispo']]\n",
    "\n",
    "print(\"âœ… ICU cohort criteria applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Demographics and Create Final Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patient demographics\n",
    "print(\"Adding patient demographics...\")\n",
    "\n",
    "# Rename columns for consistency with CLIF 2.0\n",
    "patient_df_clean = patient_df.rename(columns={\n",
    "    'race_category': 'race',\n",
    "    'ethnicity_category': 'ethnicity',\n",
    "    'sex_category': 'sex'\n",
    "})\n",
    "\n",
    "# Merge with patient data\n",
    "icu_data = pd.merge(\n",
    "    icu_data,\n",
    "    patient_df_clean[['patient_id', 'sex', 'ethnicity', 'race']],\n",
    "    on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter out records with missing sex (data quality)\n",
    "icu_data = icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final cohort with demographics: {len(icu_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final cohort table with required columns\n",
    "print(\"Creating final cohort table...\")\n",
    "\n",
    "# Create disposition binary variable (1 = expired, 0 = survived)\n",
    "icu_data['disposition'] = (icu_data['dispo'].fillna('Other').str.contains('dead|expired|death|died', case=False, regex=True)).astype(int)\n",
    "\n",
    "# Create final cohort with PRD required columns\n",
    "cohort_final = icu_data[[\n",
    "    'hospitalization_id',\n",
    "    'min_in_dttm',     # start_dttm\n",
    "    'after_24hr',      # hour_24_end_dttm\n",
    "    'disposition'\n",
    "]].rename(columns={\n",
    "    'min_in_dttm': 'start_dttm',\n",
    "    'after_24hr': 'hour_24_end_dttm'\n",
    "})\n",
    "\n",
    "# Add hour_24_start_dttm (same as start_dttm for our cohort)\n",
    "cohort_final['hour_24_start_dttm'] = cohort_final['start_dttm']\n",
    "\n",
    "# Reorder columns as per PRD\n",
    "cohort_final = cohort_final[[\n",
    "    'hospitalization_id',\n",
    "    'start_dttm',\n",
    "    'hour_24_start_dttm',\n",
    "    'hour_24_end_dttm',\n",
    "    'disposition'\n",
    "]]\n",
    "\n",
    "print(f\"âœ… Final cohort created: {len(cohort_final)} hospitalizations\")\n",
    "print(f\"Mortality rate: {cohort_final['disposition'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_final['disposition'].value_counts()*100/cohort_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Summary and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cohort summary\n",
    "print(\"=== ICU Cohort Summary ===\")\n",
    "print(f\"Total hospitalizations: {len(cohort_final):,}\")\n",
    "print(f\"Mortality rate: {cohort_final['disposition'].mean():.3f} ({cohort_final['disposition'].sum():,} deaths)\")\n",
    "print(f\"Survival rate: {1 - cohort_final['disposition'].mean():.3f} ({(cohort_final['disposition'] == 0).sum():,} survivors)\")\n",
    "\n",
    "# Time range analysis\n",
    "print(f\"\\n=== Time Range Analysis ===\")\n",
    "print(f\"Cohort start date: {cohort_final['start_dttm'].min()}\")\n",
    "print(f\"Cohort end date: {cohort_final['start_dttm'].max()}\")\n",
    "print(f\"24-hour window duration: {(cohort_final['hour_24_end_dttm'] - cohort_final['hour_24_start_dttm']).iloc[0]}\")\n",
    "\n",
    "# Validation checks\n",
    "print(f\"\\n=== Validation Checks ===\")\n",
    "print(f\"All 24-hour windows are exactly 24 hours: {((cohort_final['hour_24_end_dttm'] - cohort_final['hour_24_start_dttm']).dt.total_seconds() == 24*3600).all()}\")\n",
    "print(f\"No missing hospitalization IDs: {cohort_final['hospitalization_id'].isna().sum() == 0}\")\n",
    "print(f\"All start times before end times: {(cohort_final['start_dttm'] <= cohort_final['hour_24_end_dttm']).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cohort to Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save cohort to protected_outputs/preprocessing directory\noutput_path = os.path.join('..', 'protected_outputs', 'preprocessing', 'icu_cohort.parquet')\ncohort_final.to_parquet(output_path, index=False)\n\nprint(f\"âœ… Cohort saved to: {output_path}\")\nprint(f\"File size: {os.path.getsize(output_path) / 1024:.1f} KB\")\nprint(f\"Shape: {cohort_final.shape}\")\n\n# Save additional metadata\nmetadata = {\n    'cohort_size': len(cohort_final),\n    'mortality_rate': float(cohort_final['disposition'].mean()),\n    'date_range': {\n        'start': cohort_final['start_dttm'].min().isoformat(),\n        'end': cohort_final['start_dttm'].max().isoformat()\n    },\n    'criteria': {\n        'min_age': 18,\n        'years': '2020-2021',\n        'icu_window': '48_hours_from_admission',\n        'min_icu_duration': '24_hours',\n        'icu_or_icu_handling': 'continuous_icu'\n    }\n}\n\nmetadata_path = os.path.join('..', 'protected_outputs', 'preprocessing', 'cohort_metadata.json')\nwith open(metadata_path, 'w') as f:\n    json.dump(metadata, f, indent=2)\n\nprint(f\"âœ… Metadata saved to: {metadata_path}\")\nprint(\"\\nðŸŽ‰ Cohort generation completed successfully!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flameICU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}